paths:
  base_dir: "/home/dcunhrya/vista_bench"
  results_dir: "/home/dcunhrya/results"
  valid_tasks: "tasks/valid_tasks.json"
  prompts: "tasks/prompts_by_task.json"

model:
  device: "cuda"

runtime:
  cache_dir: "/home/dcunhrya/model_cache"
  batch_size: 10
  max_new_tokens: 1024

models:
  - type: "intern"
    name: "OpenGVLab/InternVL3_5-8B"
  
  # - type: "gemma3"
  #   name: "google/medgemma-1.5-4b-it"

  # - type: "gemma3"
  #   name: "google/medgemma-4b-it"

  # - type: "octomed"
  #   name: "OctoMed/OctoMed-7B"

  # - type: "qwen3vl"
  #   name: "Qwen/Qwen3-VL-8B-Instruct"

tasks:
  - radiation_oligoprogression_answer
  - radiation_outcome
  - progression_assessment_discussed
  - pneumonitis_infection_discussed
  - pneumonitis_infection_answer

experiments:
  - no_image
  # - axial_1_image
  - all_image
  - axial_all_image
  - sagittal_all_image

# Timeline truncation configuration
# Choose one of two modes:
# 1. 'max_chars': Truncate to first N characters (specify max_chars)
# 2. 'last_k_events': Take the last k patient events (specify k)
# Events are identified by the pattern: [YYYY-MM-DD HH:MM] |
timeline_truncation:
  mode: "last_k_events"  # Options: "max_chars" or "last_k_events"
  # max_chars: 5000     # Used when mode is "max_chars"
  k: 5             # Used when mode is "last_k_events"