{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eb920ffe-395c-4281-9bf3-b64d1349dc04",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/pasteur/u/rdcunha/code/mmbu/inference/.venv/lib/python3.13/site-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.\n",
      "  import pynvml  # type: ignore[import]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 12-28 13:49:19 [__init__.py:216] Automatically detected platform cuda.\n"
     ]
    }
   ],
   "source": [
    "from run_vlm_eval import main, load_config, set_envs, log_first_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dfdfc3a5-151e-417b-a7fb-e5043224d52c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import yaml\n",
    "import torch, gc\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from vqa_dataset import PromptDataset, prompt_collate, create_template\n",
    "from models import load_model_adapter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bae90eb8-ecba-4376-9680-2c29e58d3ff5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cfg = load_config(\"../configs/test_config.yaml\")\n",
    "model_cfg = cfg[\"model\"]\n",
    "tasks_cfg = cfg[\"tasks\"]\n",
    "run_cfg  = cfg[\"runtime\"]\n",
    "output_dir = '/pasteur/u/rdcunha/code/mmbu/results'\n",
    "\n",
    "model_type = model_cfg[\"type\"]\n",
    "model_name = model_cfg[\"name\"]\n",
    "device     = model_cfg.get(\"device\", \"auto\")\n",
    "cache_dir  = \"/pasteur/u/rdcunha/models\"\n",
    "\n",
    "set_envs(cache_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "85acf242-67cd-4d99-8659-28b78b61720a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5462cbd9224f48f5ae130c0474db50bf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using a slow image processor as `use_fast` is unset and a slow processor was saved with this model. `use_fast=True` will be the default behavior in v4.52, even if the model was saved with a slow processor. This will result in minor differences in outputs. You'll still be able to use a slow processor with `use_fast=False`.\n"
     ]
    }
   ],
   "source": [
    "adapter = load_model_adapter(model_type, model_name, device, cache_dir)\n",
    "model, processor = adapter.load()\n",
    "\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "file_model_name = model_name.split('/')[-1]\n",
    "model_path = file_model_name.replace('/', '_')\n",
    "output_dir = os.path.join(output_dir, model_path)\n",
    "os.makedirs(output_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9f0769cc-2b58-45be-8d48-5431d75e0205",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running task: segmentation_grounding_closed_VQA\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference:  95%|████████████▎| 582/613 [02:09<00:06,  4.52it/s]The following generation flags are not valid and may be ignored: ['top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Inference:  95%|████████████▎| 583/613 [02:49<06:02, 12.08s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Inference:  95%|████████████▍| 584/613 [04:04<14:58, 30.98s/it]A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Inference:  95%|████████████▍| 584/613 [04:14<00:12,  2.30it/s]\n"
     ]
    },
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 3.47 GiB. GPU 0 has a total capacity of 44.39 GiB of which 2.28 GiB is free. Including non-PyTorch memory, this process has 42.11 GiB memory in use. Of the allocated memory 34.78 GiB is allocated by PyTorch, and 6.83 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mOutOfMemoryError\u001b[39m                          Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 55\u001b[39m\n\u001b[32m     51\u001b[39m     all_inputs.append(single_inp)\n\u001b[32m     53\u001b[39m batched_inputs = adapter.stack_inputs(all_inputs, model)\n\u001b[32m---> \u001b[39m\u001b[32m55\u001b[39m outputs = \u001b[43madapter\u001b[49m\u001b[43m.\u001b[49m\u001b[43minfer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprocessor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatched_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_cfg\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmax_new_tokens\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     56\u001b[39m \u001b[38;5;66;03m# except: \u001b[39;00m\n\u001b[32m     57\u001b[39m \u001b[38;5;66;03m#     print(f\"could not generate for {batch}\")\u001b[39;00m\n\u001b[32m     58\u001b[39m \u001b[38;5;66;03m#     continue\u001b[39;00m\n\u001b[32m     59\u001b[39m \n\u001b[32m     60\u001b[39m \u001b[38;5;66;03m# log first batch only\u001b[39;00m\n\u001b[32m     61\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m run_cfg[\u001b[33m\"\u001b[39m\u001b[33mlog_first_batch\u001b[39m\u001b[33m\"\u001b[39m] \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m first_batch_logged:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/pasteur/u/rdcunha/code/mmbu/inference/src/models/gemma3.py:36\u001b[39m, in \u001b[36mGemma3Adapter.infer\u001b[39m\u001b[34m(self, model, processor, inputs, max_new_tokens)\u001b[39m\n\u001b[32m     34\u001b[39m input_len = inputs[\u001b[33m\"\u001b[39m\u001b[33minput_ids\u001b[39m\u001b[33m\"\u001b[39m].shape[-\u001b[32m1\u001b[39m]\n\u001b[32m     35\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m torch.inference_mode():\n\u001b[32m---> \u001b[39m\u001b[32m36\u001b[39m     generation = \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     37\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     38\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmax_new_tokens\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmax_new_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     39\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdo_sample\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\n\u001b[32m     40\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     41\u001b[39m outputs = []\n\u001b[32m     42\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m g \u001b[38;5;129;01min\u001b[39;00m generation:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/pasteur/u/rdcunha/code/mmbu/inference/.venv/lib/python3.13/site-packages/torch/utils/_contextlib.py:120\u001b[39m, in \u001b[36mcontext_decorator.<locals>.decorate_context\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    117\u001b[39m \u001b[38;5;129m@functools\u001b[39m.wraps(func)\n\u001b[32m    118\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mdecorate_context\u001b[39m(*args, **kwargs):\n\u001b[32m    119\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[32m--> \u001b[39m\u001b[32m120\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/pasteur/u/rdcunha/code/mmbu/inference/.venv/lib/python3.13/site-packages/transformers/generation/utils.py:2564\u001b[39m, in \u001b[36mGenerationMixin.generate\u001b[39m\u001b[34m(self, inputs, generation_config, logits_processor, stopping_criteria, prefix_allowed_tokens_fn, synced_gpus, assistant_model, streamer, negative_prompt_ids, negative_prompt_attention_mask, use_model_defaults, custom_generate, **kwargs)\u001b[39m\n\u001b[32m   2561\u001b[39m model_kwargs[\u001b[33m\"\u001b[39m\u001b[33muse_cache\u001b[39m\u001b[33m\"\u001b[39m] = generation_config.use_cache\n\u001b[32m   2563\u001b[39m \u001b[38;5;66;03m# 9. Call generation mode\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m2564\u001b[39m result = \u001b[43mdecoding_method\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2565\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   2566\u001b[39m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2567\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlogits_processor\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprepared_logits_processor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2568\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstopping_criteria\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprepared_stopping_criteria\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2569\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgeneration_config\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgeneration_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2570\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mgeneration_mode_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2571\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mmodel_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2572\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2574\u001b[39m \u001b[38;5;66;03m# Convert to legacy cache format if requested\u001b[39;00m\n\u001b[32m   2575\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m   2576\u001b[39m     generation_config.return_legacy_cache \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m   2577\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(result, \u001b[33m\"\u001b[39m\u001b[33mpast_key_values\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m   2578\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(result.past_key_values, \u001b[33m\"\u001b[39m\u001b[33mto_legacy_cache\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   2579\u001b[39m ):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/pasteur/u/rdcunha/code/mmbu/inference/.venv/lib/python3.13/site-packages/transformers/generation/utils.py:2784\u001b[39m, in \u001b[36mGenerationMixin._sample\u001b[39m\u001b[34m(self, input_ids, logits_processor, stopping_criteria, generation_config, synced_gpus, streamer, **model_kwargs)\u001b[39m\n\u001b[32m   2781\u001b[39m model_inputs = \u001b[38;5;28mself\u001b[39m.prepare_inputs_for_generation(input_ids, **model_kwargs)\n\u001b[32m   2783\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_prefill:\n\u001b[32m-> \u001b[39m\u001b[32m2784\u001b[39m     outputs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mmodel_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m   2785\u001b[39m     is_prefill = \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m   2786\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/pasteur/u/rdcunha/code/mmbu/inference/.venv/lib/python3.13/site-packages/torch/nn/modules/module.py:1773\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1771\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1772\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/pasteur/u/rdcunha/code/mmbu/inference/.venv/lib/python3.13/site-packages/torch/nn/modules/module.py:1784\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1779\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1780\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1781\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1782\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1783\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1784\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1786\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1787\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/pasteur/u/rdcunha/code/mmbu/inference/.venv/lib/python3.13/site-packages/transformers/models/gemma3/modeling_gemma3.py:1100\u001b[39m, in \u001b[36mGemma3ForConditionalGeneration.forward\u001b[39m\u001b[34m(self, input_ids, pixel_values, attention_mask, position_ids, past_key_values, token_type_ids, cache_position, inputs_embeds, labels, use_cache, output_attentions, output_hidden_states, return_dict, logits_to_keep, **lm_kwargs)\u001b[39m\n\u001b[32m   1095\u001b[39m output_hidden_states = (\n\u001b[32m   1096\u001b[39m     output_hidden_states \u001b[38;5;28;01mif\u001b[39;00m output_hidden_states \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m.config.output_hidden_states\n\u001b[32m   1097\u001b[39m )\n\u001b[32m   1098\u001b[39m return_dict = return_dict \u001b[38;5;28;01mif\u001b[39;00m return_dict \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m.config.use_return_dict\n\u001b[32m-> \u001b[39m\u001b[32m1100\u001b[39m outputs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1101\u001b[39m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m=\u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1102\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpixel_values\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpixel_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1103\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtoken_type_ids\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtoken_type_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1104\u001b[39m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1105\u001b[39m \u001b[43m    \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[43m=\u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1106\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1107\u001b[39m \u001b[43m    \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[43m=\u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1108\u001b[39m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[43m=\u001b[49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1109\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1110\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1111\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1112\u001b[39m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[43m=\u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1113\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcache_position\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcache_position\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1114\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mlm_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1115\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1117\u001b[39m hidden_states = outputs[\u001b[32m0\u001b[39m]\n\u001b[32m   1118\u001b[39m \u001b[38;5;66;03m# Only compute necessary logits, and do not upcast them to float if we are not computing the loss\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/pasteur/u/rdcunha/code/mmbu/inference/.venv/lib/python3.13/site-packages/torch/nn/modules/module.py:1773\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1771\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1772\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/pasteur/u/rdcunha/code/mmbu/inference/.venv/lib/python3.13/site-packages/torch/nn/modules/module.py:1784\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1779\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1780\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1781\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1782\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1783\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1784\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1786\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1787\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/pasteur/u/rdcunha/code/mmbu/inference/.venv/lib/python3.13/site-packages/transformers/utils/generic.py:918\u001b[39m, in \u001b[36mcan_return_tuple.<locals>.wrapper\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    916\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m return_dict_passed \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    917\u001b[39m     return_dict = return_dict_passed\n\u001b[32m--> \u001b[39m\u001b[32m918\u001b[39m output = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    919\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m return_dict \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(output, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[32m    920\u001b[39m     output = output.to_tuple()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/pasteur/u/rdcunha/code/mmbu/inference/.venv/lib/python3.13/site-packages/transformers/models/gemma3/modeling_gemma3.py:957\u001b[39m, in \u001b[36mGemma3Model.forward\u001b[39m\u001b[34m(self, input_ids, pixel_values, attention_mask, position_ids, past_key_values, token_type_ids, cache_position, inputs_embeds, labels, use_cache, output_attentions, output_hidden_states, return_dict, **lm_kwargs)\u001b[39m\n\u001b[32m    951\u001b[39m     \u001b[38;5;66;03m# Create the masks\u001b[39;00m\n\u001b[32m    952\u001b[39m     causal_mask_mapping = {\n\u001b[32m    953\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mfull_attention\u001b[39m\u001b[33m\"\u001b[39m: create_causal_mask(**mask_kwargs),\n\u001b[32m    954\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33msliding_attention\u001b[39m\u001b[33m\"\u001b[39m: create_sliding_window_causal_mask(**mask_kwargs),\n\u001b[32m    955\u001b[39m     }\n\u001b[32m--> \u001b[39m\u001b[32m957\u001b[39m outputs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mlanguage_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    958\u001b[39m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcausal_mask_mapping\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    959\u001b[39m \u001b[43m    \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[43m=\u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    960\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    961\u001b[39m \u001b[43m    \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[43m=\u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    962\u001b[39m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[43m=\u001b[49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    963\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    964\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    965\u001b[39m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    966\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcache_position\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcache_position\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    967\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mlm_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    968\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    970\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m Gemma3ModelOutputWithPast(\n\u001b[32m    971\u001b[39m     last_hidden_state=outputs.last_hidden_state,\n\u001b[32m    972\u001b[39m     past_key_values=outputs.past_key_values \u001b[38;5;28;01mif\u001b[39;00m use_cache \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    975\u001b[39m     image_hidden_states=image_features \u001b[38;5;28;01mif\u001b[39;00m pixel_values \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m    976\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/pasteur/u/rdcunha/code/mmbu/inference/.venv/lib/python3.13/site-packages/torch/nn/modules/module.py:1773\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1771\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1772\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/pasteur/u/rdcunha/code/mmbu/inference/.venv/lib/python3.13/site-packages/torch/nn/modules/module.py:1784\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1779\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1780\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1781\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1782\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1783\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1784\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1786\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1787\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/pasteur/u/rdcunha/code/mmbu/inference/.venv/lib/python3.13/site-packages/transformers/utils/generic.py:1064\u001b[39m, in \u001b[36mcheck_model_inputs.<locals>.wrapper\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1061\u001b[39m                 monkey_patched_layers.append((module, original_forward))\n\u001b[32m   1063\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1064\u001b[39m     outputs = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1065\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m original_exception:\n\u001b[32m   1066\u001b[39m     \u001b[38;5;66;03m# If we get a TypeError, it's possible that the model is not receiving the recordable kwargs correctly.\u001b[39;00m\n\u001b[32m   1067\u001b[39m     \u001b[38;5;66;03m# Get a TypeError even after removing the recordable kwargs -> re-raise the original exception\u001b[39;00m\n\u001b[32m   1068\u001b[39m     \u001b[38;5;66;03m# Otherwise -> we're probably missing `**kwargs` in the decorated function\u001b[39;00m\n\u001b[32m   1069\u001b[39m     kwargs_without_recordable = {k: v \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m kwargs.items() \u001b[38;5;28;01mif\u001b[39;00m k \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m recordable_keys}\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/pasteur/u/rdcunha/code/mmbu/inference/.venv/lib/python3.13/site-packages/transformers/models/gemma3/modeling_gemma3.py:570\u001b[39m, in \u001b[36mGemma3TextModel.forward\u001b[39m\u001b[34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, use_cache, output_attentions, output_hidden_states, cache_position, **kwargs)\u001b[39m\n\u001b[32m    567\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m output_hidden_states:\n\u001b[32m    568\u001b[39m     all_hidden_states += (hidden_states,)\n\u001b[32m--> \u001b[39m\u001b[32m570\u001b[39m layer_outputs = \u001b[43mdecoder_layer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    571\u001b[39m \u001b[43m    \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    572\u001b[39m \u001b[43m    \u001b[49m\u001b[43mposition_embeddings_global\u001b[49m\u001b[43m=\u001b[49m\u001b[43mposition_embeddings_global\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    573\u001b[39m \u001b[43m    \u001b[49m\u001b[43mposition_embeddings_local\u001b[49m\u001b[43m=\u001b[49m\u001b[43mposition_embeddings_local\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    574\u001b[39m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcausal_mask_mapping\u001b[49m\u001b[43m[\u001b[49m\u001b[43mdecoder_layer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mattention_type\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    575\u001b[39m \u001b[43m    \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[43m=\u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    576\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    577\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    578\u001b[39m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[43m=\u001b[49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    579\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcache_position\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcache_position\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    580\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    581\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    583\u001b[39m hidden_states = layer_outputs[\u001b[32m0\u001b[39m]\n\u001b[32m    585\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m output_attentions:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/pasteur/u/rdcunha/code/mmbu/inference/.venv/lib/python3.13/site-packages/transformers/modeling_layers.py:94\u001b[39m, in \u001b[36mGradientCheckpointingLayer.__call__\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m     91\u001b[39m         logger.warning_once(message)\n\u001b[32m     93\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._gradient_checkpointing_func(partial(\u001b[38;5;28msuper\u001b[39m().\u001b[34m__call__\u001b[39m, **kwargs), *args)\n\u001b[32m---> \u001b[39m\u001b[32m94\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/pasteur/u/rdcunha/code/mmbu/inference/.venv/lib/python3.13/site-packages/torch/nn/modules/module.py:1773\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1771\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1772\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/pasteur/u/rdcunha/code/mmbu/inference/.venv/lib/python3.13/site-packages/torch/nn/modules/module.py:1784\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1779\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1780\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1781\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1782\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1783\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1784\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1786\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1787\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/pasteur/u/rdcunha/code/mmbu/inference/.venv/lib/python3.13/site-packages/transformers/utils/deprecation.py:172\u001b[39m, in \u001b[36mdeprecate_kwarg.<locals>.wrapper.<locals>.wrapped_func\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    168\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m minimum_action \u001b[38;5;129;01min\u001b[39;00m (Action.NOTIFY, Action.NOTIFY_ALWAYS) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_torchdynamo_compiling():\n\u001b[32m    169\u001b[39m     \u001b[38;5;66;03m# DeprecationWarning is ignored by default, so we use FutureWarning instead\u001b[39;00m\n\u001b[32m    170\u001b[39m     warnings.warn(message, \u001b[38;5;167;01mFutureWarning\u001b[39;00m, stacklevel=\u001b[32m2\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m172\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/pasteur/u/rdcunha/code/mmbu/inference/.venv/lib/python3.13/site-packages/transformers/models/gemma3/modeling_gemma3.py:398\u001b[39m, in \u001b[36mGemma3DecoderLayer.forward\u001b[39m\u001b[34m(self, hidden_states, position_embeddings_global, position_embeddings_local, attention_mask, position_ids, past_key_values, output_attentions, use_cache, cache_position, **kwargs)\u001b[39m\n\u001b[32m    396\u001b[39m residual = hidden_states\n\u001b[32m    397\u001b[39m hidden_states = \u001b[38;5;28mself\u001b[39m.pre_feedforward_layernorm(hidden_states)\n\u001b[32m--> \u001b[39m\u001b[32m398\u001b[39m hidden_states = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmlp\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    399\u001b[39m hidden_states = \u001b[38;5;28mself\u001b[39m.post_feedforward_layernorm(hidden_states)\n\u001b[32m    400\u001b[39m hidden_states = residual + hidden_states\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/pasteur/u/rdcunha/code/mmbu/inference/.venv/lib/python3.13/site-packages/torch/nn/modules/module.py:1773\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1771\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1772\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/pasteur/u/rdcunha/code/mmbu/inference/.venv/lib/python3.13/site-packages/torch/nn/modules/module.py:1784\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1779\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1780\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1781\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1782\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1783\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1784\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1786\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1787\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/pasteur/u/rdcunha/code/mmbu/inference/.venv/lib/python3.13/site-packages/transformers/models/gemma3/modeling_gemma3.py:122\u001b[39m, in \u001b[36mGemma3MLP.forward\u001b[39m\u001b[34m(self, x)\u001b[39m\n\u001b[32m    121\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[32m--> \u001b[39m\u001b[32m122\u001b[39m     down_proj = \u001b[38;5;28mself\u001b[39m.down_proj(\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mact_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgate_proj\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mup_proj\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[32m    123\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m down_proj\n",
      "\u001b[31mOutOfMemoryError\u001b[39m: CUDA out of memory. Tried to allocate 3.47 GiB. GPU 0 has a total capacity of 44.39 GiB of which 2.28 GiB is free. Including non-PyTorch memory, this process has 42.11 GiB memory in use. Of the allocated memory 34.78 GiB is allocated by PyTorch, and 6.83 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
     ]
    }
   ],
   "source": [
    "base_path = '/pasteur/u/rdcunha/data_cache/mmbu/final_data/subsampled_mmbu_data'\n",
    "\n",
    "for task_cfg in tasks_cfg:\n",
    "    print(f'Running task: {task_cfg['name']}')\n",
    "    out_file = os.path.join(output_dir, f\"{file_model_name.replace('/', '_')}_{task_cfg['name']}.jsonl\")\n",
    "    tsv_path = os.path.join(base_path, task_cfg[\"data_path\"])\n",
    "    df = pd.read_csv(tsv_path, sep='\\t')\n",
    "    \n",
    "    add_options = (\"open\" not in task_cfg[\"name\"])\n",
    "    dataset = PromptDataset(df=df, add_options=add_options)\n",
    "    loader = DataLoader(\n",
    "        dataset,\n",
    "        batch_size=run_cfg[\"batch_size\"],\n",
    "        shuffle=False,\n",
    "        collate_fn=prompt_collate,\n",
    "        num_workers=2,\n",
    "        persistent_workers=True,\n",
    "        pin_memory=True,\n",
    "        prefetch_factor=2\n",
    "    )\n",
    "\n",
    "    existing = set()\n",
    "    if os.path.exists(out_file):\n",
    "        with open(out_file, \"r\") as f:\n",
    "            for line in f:\n",
    "                try:\n",
    "                    j = json.loads(line)\n",
    "                    existing.add(j[\"index\"])\n",
    "                except:\n",
    "                    pass\n",
    "                    \n",
    "    counter = 0\n",
    "    saved = []\n",
    "    first_batch_logged = False\n",
    "    \n",
    "    with open(out_file, \"a\") as f:\n",
    "        for batch in tqdm(loader, desc=\"Inference\"):\n",
    "            gc.collect()\n",
    "            torch.cuda.empty_cache()\n",
    "    \n",
    "            new_batch = [x for x in batch if x[\"index\"] not in existing]\n",
    "            if not new_batch:\n",
    "                continue\n",
    "    \n",
    "            # inference\n",
    "            # try:\n",
    "            all_inputs = []\n",
    "            for item in new_batch:\n",
    "                single_msg = adapter.create_template(item)\n",
    "                single_inp = adapter.prepare_inputs([single_msg], processor, model)\n",
    "                all_inputs.append(single_inp)\n",
    "            \n",
    "            batched_inputs = adapter.stack_inputs(all_inputs, model)\n",
    "            \n",
    "            outputs = adapter.infer(model, processor, batched_inputs, run_cfg[\"max_new_tokens\"])\n",
    "            # except: \n",
    "            #     print(f\"could not generate for {batch}\")\n",
    "            #     continue\n",
    "    \n",
    "            # log first batch only\n",
    "            if run_cfg[\"log_first_batch\"] and not first_batch_logged:\n",
    "                log_first_batch(outputs, output_dir)\n",
    "                first_batch_logged = True\n",
    "    \n",
    "            # save results\n",
    "            for it, out_text in zip(new_batch, outputs):\n",
    "                obj = {\n",
    "                    \"index\": it[\"index\"],\n",
    "                    \"question\": it[\"question\"],\n",
    "                    \"image_path\": it[\"image_path\"],\n",
    "                    \"dataset\": it[\"dataset\"],\n",
    "                    \"modality\": it[\"modality\"],\n",
    "                    \"class_label\": it[\"class_label\"],\n",
    "                    \"answer\": out_text\n",
    "                }\n",
    "                if \"options\" in it and it[\"options\"] is not None:\n",
    "                    obj[\"options\"] = it[\"options\"]\n",
    "            \n",
    "                saved.append(obj)\n",
    "                existing.add(it[\"index\"])\n",
    "                counter += 1\n",
    "    \n",
    "                if counter % 50 == 0:\n",
    "                    for s in saved:\n",
    "                        f.write(json.dumps(s) + \"\\n\")\n",
    "                    f.flush()\n",
    "                    saved = []\n",
    "    \n",
    "        # Save remainder\n",
    "        for s in saved:\n",
    "            f.write(json.dumps(s) + \"\\n\")\n",
    "\n",
    "print('Completed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8239246f-f27d-446f-99d7-576138c60b6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows: 3064\n",
      "Unique image paths: 1768\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e1a6c3300f4343148043bd25dfc912a8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Scanning image sizes:   0%|          | 0/1768 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original length: 3064\n",
      "\n",
      "Readable images: 1768\n",
      "Images with width>512 OR height>512: 28\n",
      "Images with width>=512 AND height>=512 (your pad_to_512 keeps full-res): 567\n",
      "Errors/missing: 0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from tqdm.auto import tqdm\n",
    "from pathlib import Path\n",
    "\n",
    "tsv_path = Path(\"/pasteur/u/rdcunha/data_cache/mmbu/final_data/subsampled_mmbu_data/final_seg/final_subsampled_seg_grounding_closed_12_29.tsv\")\n",
    "\n",
    "# 1) Load TSV\n",
    "df = pd.read_csv(tsv_path, sep=\"\\t\")\n",
    "assert \"image_path\" in df.columns, f\"Expected column 'image_path' in TSV. Columns: {list(df.columns)}\"\n",
    "\n",
    "paths = df[\"image_path\"].astype(str).fillna(\"\")\n",
    "unique_paths = pd.unique(paths)\n",
    "\n",
    "print(\"Rows:\", len(df))\n",
    "print(\"Unique image paths:\", len(unique_paths))\n",
    "\n",
    "rows = []\n",
    "errors = []\n",
    "\n",
    "for p in tqdm(unique_paths, desc=\"Scanning image sizes\"):\n",
    "    p = p.strip()\n",
    "    if not p or p.lower() in {\"nan\", \"none\"}:\n",
    "        errors.append((p, \"empty/NaN path\"))\n",
    "        continue\n",
    "    if not os.path.exists(p):\n",
    "        errors.append((p, \"path does not exist\"))\n",
    "        continue\n",
    "\n",
    "    try:\n",
    "        # size doesn't require decoding full image into RAM\n",
    "        with Image.open(p) as img:\n",
    "            w, h = img.size\n",
    "            mode = img.mode\n",
    "        rows.append((p, w, h, w*h, mode))\n",
    "    except Exception as e:\n",
    "        errors.append((p, repr(e)))\n",
    "\n",
    "sizes = pd.DataFrame(rows, columns=[\"image_path\", \"width\", \"height\", \"area\", \"mode\"])\n",
    "\n",
    "# 2) Flags\n",
    "sizes[\"gt_512_any\"] = (sizes[\"width\"] > 512) | (sizes[\"height\"] > 512)\n",
    "sizes[\"ge_512_both\"] = (sizes[\"width\"] >= 512) & (sizes[\"height\"] >= 512)\n",
    "\n",
    "gt_any = sizes[sizes[\"gt_512_any\"]].sort_values(\"area\", ascending=False)\n",
    "ge_both = sizes[sizes[\"ge_512_both\"]].sort_values(\"area\", ascending=False)\n",
    "\n",
    "print(f\"Original length: {len(df)}\")\n",
    "print(f\"\\nReadable images: {len(sizes)}\")\n",
    "print(f\"Images with width>512 OR height>512: {len(gt_any)}\")\n",
    "print(f\"Images with width>=512 AND height>=512 (your pad_to_512 keeps full-res): {len(ge_both)}\")\n",
    "print(f\"Errors/missing: {len(errors)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bb03598b-6e92-4f9f-bcdc-60f9fdf8e895",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "TSV rows with width>512 OR height>512: 28\n",
      "Unique indices affected: 28\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>image_path</th>\n",
       "      <th>width</th>\n",
       "      <th>height</th>\n",
       "      <th>mode</th>\n",
       "      <th>area</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2464</td>\n",
       "      <td>/pasteur/u/rdcunha/data_cache/mmbu/final_data/...</td>\n",
       "      <td>1280</td>\n",
       "      <td>1024</td>\n",
       "      <td>RGB</td>\n",
       "      <td>1310720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2466</td>\n",
       "      <td>/pasteur/u/rdcunha/data_cache/mmbu/final_data/...</td>\n",
       "      <td>1280</td>\n",
       "      <td>1024</td>\n",
       "      <td>RGB</td>\n",
       "      <td>1310720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2467</td>\n",
       "      <td>/pasteur/u/rdcunha/data_cache/mmbu/final_data/...</td>\n",
       "      <td>1280</td>\n",
       "      <td>1024</td>\n",
       "      <td>RGB</td>\n",
       "      <td>1310720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2468</td>\n",
       "      <td>/pasteur/u/rdcunha/data_cache/mmbu/final_data/...</td>\n",
       "      <td>1280</td>\n",
       "      <td>1024</td>\n",
       "      <td>RGB</td>\n",
       "      <td>1310720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2469</td>\n",
       "      <td>/pasteur/u/rdcunha/data_cache/mmbu/final_data/...</td>\n",
       "      <td>1280</td>\n",
       "      <td>1024</td>\n",
       "      <td>RGB</td>\n",
       "      <td>1310720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2470</td>\n",
       "      <td>/pasteur/u/rdcunha/data_cache/mmbu/final_data/...</td>\n",
       "      <td>1280</td>\n",
       "      <td>1024</td>\n",
       "      <td>RGB</td>\n",
       "      <td>1310720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2471</td>\n",
       "      <td>/pasteur/u/rdcunha/data_cache/mmbu/final_data/...</td>\n",
       "      <td>1280</td>\n",
       "      <td>1024</td>\n",
       "      <td>RGB</td>\n",
       "      <td>1310720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2472</td>\n",
       "      <td>/pasteur/u/rdcunha/data_cache/mmbu/final_data/...</td>\n",
       "      <td>1280</td>\n",
       "      <td>1024</td>\n",
       "      <td>RGB</td>\n",
       "      <td>1310720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>2712</td>\n",
       "      <td>/pasteur/u/rdcunha/data_cache/mmbu/final_data/...</td>\n",
       "      <td>1024</td>\n",
       "      <td>768</td>\n",
       "      <td>RGB</td>\n",
       "      <td>786432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2424</td>\n",
       "      <td>/pasteur/u/rdcunha/data_cache/mmbu/final_data/...</td>\n",
       "      <td>856</td>\n",
       "      <td>606</td>\n",
       "      <td>RGB</td>\n",
       "      <td>518736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2425</td>\n",
       "      <td>/pasteur/u/rdcunha/data_cache/mmbu/final_data/...</td>\n",
       "      <td>856</td>\n",
       "      <td>606</td>\n",
       "      <td>RGB</td>\n",
       "      <td>518736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2426</td>\n",
       "      <td>/pasteur/u/rdcunha/data_cache/mmbu/final_data/...</td>\n",
       "      <td>856</td>\n",
       "      <td>606</td>\n",
       "      <td>RGB</td>\n",
       "      <td>518736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2427</td>\n",
       "      <td>/pasteur/u/rdcunha/data_cache/mmbu/final_data/...</td>\n",
       "      <td>856</td>\n",
       "      <td>606</td>\n",
       "      <td>RGB</td>\n",
       "      <td>518736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2428</td>\n",
       "      <td>/pasteur/u/rdcunha/data_cache/mmbu/final_data/...</td>\n",
       "      <td>856</td>\n",
       "      <td>606</td>\n",
       "      <td>RGB</td>\n",
       "      <td>518736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2429</td>\n",
       "      <td>/pasteur/u/rdcunha/data_cache/mmbu/final_data/...</td>\n",
       "      <td>856</td>\n",
       "      <td>606</td>\n",
       "      <td>RGB</td>\n",
       "      <td>518736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2430</td>\n",
       "      <td>/pasteur/u/rdcunha/data_cache/mmbu/final_data/...</td>\n",
       "      <td>856</td>\n",
       "      <td>606</td>\n",
       "      <td>RGB</td>\n",
       "      <td>518736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2431</td>\n",
       "      <td>/pasteur/u/rdcunha/data_cache/mmbu/final_data/...</td>\n",
       "      <td>856</td>\n",
       "      <td>606</td>\n",
       "      <td>RGB</td>\n",
       "      <td>518736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2432</td>\n",
       "      <td>/pasteur/u/rdcunha/data_cache/mmbu/final_data/...</td>\n",
       "      <td>856</td>\n",
       "      <td>606</td>\n",
       "      <td>RGB</td>\n",
       "      <td>518736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2433</td>\n",
       "      <td>/pasteur/u/rdcunha/data_cache/mmbu/final_data/...</td>\n",
       "      <td>856</td>\n",
       "      <td>606</td>\n",
       "      <td>RGB</td>\n",
       "      <td>518736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2704</td>\n",
       "      <td>/pasteur/u/rdcunha/data_cache/mmbu/final_data/...</td>\n",
       "      <td>816</td>\n",
       "      <td>614</td>\n",
       "      <td>RGB</td>\n",
       "      <td>501024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2705</td>\n",
       "      <td>/pasteur/u/rdcunha/data_cache/mmbu/final_data/...</td>\n",
       "      <td>816</td>\n",
       "      <td>614</td>\n",
       "      <td>RGB</td>\n",
       "      <td>501024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>2706</td>\n",
       "      <td>/pasteur/u/rdcunha/data_cache/mmbu/final_data/...</td>\n",
       "      <td>816</td>\n",
       "      <td>614</td>\n",
       "      <td>RGB</td>\n",
       "      <td>501024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>2707</td>\n",
       "      <td>/pasteur/u/rdcunha/data_cache/mmbu/final_data/...</td>\n",
       "      <td>816</td>\n",
       "      <td>614</td>\n",
       "      <td>RGB</td>\n",
       "      <td>501024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>2708</td>\n",
       "      <td>/pasteur/u/rdcunha/data_cache/mmbu/final_data/...</td>\n",
       "      <td>816</td>\n",
       "      <td>614</td>\n",
       "      <td>RGB</td>\n",
       "      <td>501024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>2709</td>\n",
       "      <td>/pasteur/u/rdcunha/data_cache/mmbu/final_data/...</td>\n",
       "      <td>816</td>\n",
       "      <td>614</td>\n",
       "      <td>RGB</td>\n",
       "      <td>501024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>2710</td>\n",
       "      <td>/pasteur/u/rdcunha/data_cache/mmbu/final_data/...</td>\n",
       "      <td>816</td>\n",
       "      <td>614</td>\n",
       "      <td>RGB</td>\n",
       "      <td>501024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>2711</td>\n",
       "      <td>/pasteur/u/rdcunha/data_cache/mmbu/final_data/...</td>\n",
       "      <td>816</td>\n",
       "      <td>614</td>\n",
       "      <td>RGB</td>\n",
       "      <td>501024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>2713</td>\n",
       "      <td>/pasteur/u/rdcunha/data_cache/mmbu/final_data/...</td>\n",
       "      <td>816</td>\n",
       "      <td>614</td>\n",
       "      <td>RGB</td>\n",
       "      <td>501024</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    index                                         image_path  width  height  \\\n",
       "10   2464  /pasteur/u/rdcunha/data_cache/mmbu/final_data/...   1280    1024   \n",
       "11   2466  /pasteur/u/rdcunha/data_cache/mmbu/final_data/...   1280    1024   \n",
       "12   2467  /pasteur/u/rdcunha/data_cache/mmbu/final_data/...   1280    1024   \n",
       "13   2468  /pasteur/u/rdcunha/data_cache/mmbu/final_data/...   1280    1024   \n",
       "14   2469  /pasteur/u/rdcunha/data_cache/mmbu/final_data/...   1280    1024   \n",
       "15   2470  /pasteur/u/rdcunha/data_cache/mmbu/final_data/...   1280    1024   \n",
       "16   2471  /pasteur/u/rdcunha/data_cache/mmbu/final_data/...   1280    1024   \n",
       "17   2472  /pasteur/u/rdcunha/data_cache/mmbu/final_data/...   1280    1024   \n",
       "26   2712  /pasteur/u/rdcunha/data_cache/mmbu/final_data/...   1024     768   \n",
       "0    2424  /pasteur/u/rdcunha/data_cache/mmbu/final_data/...    856     606   \n",
       "1    2425  /pasteur/u/rdcunha/data_cache/mmbu/final_data/...    856     606   \n",
       "2    2426  /pasteur/u/rdcunha/data_cache/mmbu/final_data/...    856     606   \n",
       "3    2427  /pasteur/u/rdcunha/data_cache/mmbu/final_data/...    856     606   \n",
       "4    2428  /pasteur/u/rdcunha/data_cache/mmbu/final_data/...    856     606   \n",
       "5    2429  /pasteur/u/rdcunha/data_cache/mmbu/final_data/...    856     606   \n",
       "6    2430  /pasteur/u/rdcunha/data_cache/mmbu/final_data/...    856     606   \n",
       "7    2431  /pasteur/u/rdcunha/data_cache/mmbu/final_data/...    856     606   \n",
       "8    2432  /pasteur/u/rdcunha/data_cache/mmbu/final_data/...    856     606   \n",
       "9    2433  /pasteur/u/rdcunha/data_cache/mmbu/final_data/...    856     606   \n",
       "18   2704  /pasteur/u/rdcunha/data_cache/mmbu/final_data/...    816     614   \n",
       "19   2705  /pasteur/u/rdcunha/data_cache/mmbu/final_data/...    816     614   \n",
       "20   2706  /pasteur/u/rdcunha/data_cache/mmbu/final_data/...    816     614   \n",
       "21   2707  /pasteur/u/rdcunha/data_cache/mmbu/final_data/...    816     614   \n",
       "22   2708  /pasteur/u/rdcunha/data_cache/mmbu/final_data/...    816     614   \n",
       "23   2709  /pasteur/u/rdcunha/data_cache/mmbu/final_data/...    816     614   \n",
       "24   2710  /pasteur/u/rdcunha/data_cache/mmbu/final_data/...    816     614   \n",
       "25   2711  /pasteur/u/rdcunha/data_cache/mmbu/final_data/...    816     614   \n",
       "27   2713  /pasteur/u/rdcunha/data_cache/mmbu/final_data/...    816     614   \n",
       "\n",
       "   mode     area  \n",
       "10  RGB  1310720  \n",
       "11  RGB  1310720  \n",
       "12  RGB  1310720  \n",
       "13  RGB  1310720  \n",
       "14  RGB  1310720  \n",
       "15  RGB  1310720  \n",
       "16  RGB  1310720  \n",
       "17  RGB  1310720  \n",
       "26  RGB   786432  \n",
       "0   RGB   518736  \n",
       "1   RGB   518736  \n",
       "2   RGB   518736  \n",
       "3   RGB   518736  \n",
       "4   RGB   518736  \n",
       "5   RGB   518736  \n",
       "6   RGB   518736  \n",
       "7   RGB   518736  \n",
       "8   RGB   518736  \n",
       "9   RGB   518736  \n",
       "18  RGB   501024  \n",
       "19  RGB   501024  \n",
       "20  RGB   501024  \n",
       "21  RGB   501024  \n",
       "22  RGB   501024  \n",
       "23  RGB   501024  \n",
       "24  RGB   501024  \n",
       "25  RGB   501024  \n",
       "27  RGB   501024  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "([2424,\n",
       "  2425,\n",
       "  2426,\n",
       "  2427,\n",
       "  2428,\n",
       "  2429,\n",
       "  2430,\n",
       "  2431,\n",
       "  2432,\n",
       "  2433,\n",
       "  2464,\n",
       "  2466,\n",
       "  2467,\n",
       "  2468,\n",
       "  2469,\n",
       "  2470,\n",
       "  2471,\n",
       "  2472,\n",
       "  2704,\n",
       "  2705,\n",
       "  2706,\n",
       "  2707,\n",
       "  2708,\n",
       "  2709,\n",
       "  2710,\n",
       "  2711,\n",
       "  2712,\n",
       "  2713],\n",
       " 28)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# --- map back to TSV rows to get indices ---\n",
    "assert \"index\" in df.columns, f\"Expected column 'index' in TSV. Columns: {list(df.columns)}\"\n",
    "\n",
    "gt_paths = set(gt_any[\"image_path\"].tolist())\n",
    "\n",
    "df_gt = df[df[\"image_path\"].astype(str).isin(gt_paths)].copy()\n",
    "\n",
    "# Attach width/height for convenience\n",
    "df_gt = df_gt.merge(\n",
    "    gt_any[[\"image_path\", \"width\", \"height\", \"area\", \"mode\"]],\n",
    "    on=\"image_path\",\n",
    "    how=\"left\"\n",
    ").sort_values([\"area\", \"index\"], ascending=[False, True])\n",
    "\n",
    "# Unique indices (or keep all rows if you want duplicates)\n",
    "bad_indices = df_gt[\"index\"].astype(int).tolist()\n",
    "\n",
    "print(f\"\\nTSV rows with width>512 OR height>512: {len(df_gt)}\")\n",
    "print(f\"Unique indices affected: {df_gt['index'].nunique()}\")\n",
    "\n",
    "display(df_gt[[\"index\", \"image_path\", \"width\", \"height\", \"mode\", \"area\"]].head(50))\n",
    "\n",
    "# If you only want the unique index list:\n",
    "bad_indices_unique = sorted(df_gt[\"index\"].astype(int).unique().tolist())\n",
    "bad_indices_unique[:50], len(bad_indices_unique)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27645240-6ac0-4b8b-a0d0-7fcddc13dc60",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
